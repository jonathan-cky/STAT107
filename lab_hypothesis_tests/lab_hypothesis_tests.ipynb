{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab: Hypothesis Tests üìî‚ùî\n",
    "In this lab, you will conduct hypothesis tests on the Hello Dataset! \n",
    "\n",
    "A few tips to remember:\n",
    "\n",
    "- **You are not alone on your journey in learning programming!**  You have your lab TA, your CAs, your lab group, and the professors (Prof. Wade and Prof. Karle), who are all here to help you out!\n",
    "- If you find yourself stuck for more than a few minutes, ask a neighbor or course staff for help!  When you are giving help to your neighbor, explain the **idea and approach** to the problem without sharing the answer itself so they can have the same **<i>ah-hah</i>** moment!\n",
    "- We are here to help you!  Don't feel embarrassed or shy to ask us for help!\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meet your CAs and TA if you haven't already!\n",
    "# ...first name is enough, we'll know who they are! :)\n",
    "ta_name = \"\"\n",
    "ca1_name = \"\"\n",
    "ca2_name = \"\"\n",
    "ca3_name = \"\"\n",
    "\n",
    "# Say hello to each other!\n",
    "# - Groups of 3 are ideal :)\n",
    "# - However, groups of 2 or 4 are fine too!\n",
    "\n",
    "# QOTD to ask your group: What is your favorite holiday?\n",
    "partner1_name = \"\"\n",
    "partner1_netid = \"\"\n",
    "partner1_favholiday = \"\"\n",
    "\n",
    "partner2_name = \"\"\n",
    "partner2_netid = \"\"\n",
    "partner2_favholiday = \"\"\n",
    "\n",
    "partner3_name = \"\"\n",
    "partner3_netid = \"\"\n",
    "partner3_favholiday = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Sleep\n",
    "Remember the Hello Survey you took towards the beginning of the semester? Well, we are bringing it back! We're going to conduct hypothesis tests using **your Hello Dataset**. Specifically, we will answer this question: \n",
    "\n",
    "> **Do UIUC students get significantly different sleep compared to the average American?**\n",
    "\n",
    "First, as always, we must import the Hello Dataset. \n",
    "\n",
    "The \"Hello Dataset\" is available here:\n",
    "```\n",
    "https://waf.cs.illinois.edu/discovery/hello-sp24.csv\n",
    "```\n",
    "\n",
    "Use Python to load this dataset into a DataFrame called `df_hello`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED 373all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "assert(\"df_hello\" in vars()), \"This is not the Hello Dataset you're looking for. Check the URL.\"\n",
    "assert(\"Do you use Windows or Mac?\" in df_hello), \"This is not the Hello Dataset you're looking for. Check the URL.\"\n",
    "assert(len(df_hello) == 611), \"This is not the Hello Dataset you're looking for. Check the URL.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting Up The Test\n",
    "In 2013, [Gallup completed their latest survey on sleep](https://news.gallup.com/poll/166553/less-recommended-amount-sleep.aspx) that shows that the average amount of sleep Americans get is **6.8 hours**.  \n",
    "\n",
    "To determine whether UIUC students get significantly more or less sleep than the average American, we will treat the **SPRING 24 students in DISCOVERY** as a **random sample** of the student population at UIUC. Then, we will conduct a **one-sample z-test** to answer our question. \n",
    "\n",
    "Before we begin, we must define our hypotheses. Remember, the average amount of sleep found in Gallup's study is **6.8** hours, and we want to determine if our random sample is **significantly different** from this average. \n",
    "\n",
    "**Q1: Write your null and alternative hypothesis using the cell below.** *Hint: you may find the following symbol useful for the alternative hypothesis: $\\neq$ (double-click on this cell to copy it)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answer. ‚úèÔ∏è)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.1: Summary Statistics\n",
    "Now that we've defined our hypotheses, we will need to find some basic **summary statistics** about the **average hours of sleep** of students in DISCOVERY before we conduct our **z-test**. Our `df_hello` contains the average hours of sleep of students in DISCOVERY under the column named \"How many hours do you sleep in a night?\".\n",
    "\n",
    "Assign this column name to a **string variable** named `sleep_question` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_question = ...\n",
    "sleep_question"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, using `sleep_question` and your `df_hello`, find the **mean hours of sleep** of everyone in DISCOVERY, storing the result in the **variable** `sleep_mean`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_mean = ...\n",
    "sleep_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, find the **standard deviation** of hours of sleep of everyone in DISCOVERY, storing the result in the **variable** `sleep_std`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_std = ...\n",
    "sleep_std"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, find the **sample size** we're using for this z-test, storing the result in the **variable** `sample_size`. \n",
    "\n",
    "There's something a little tricky about the data we have in this column. Some people haven't filled out the answer to this captivating question, causing `NaN` (empty) values to appear. Dealing with **null values** is a **common occurrence** in data science. To exclude empty values when finding the sample size, the `.count()` function will be useful, as it excludes cells with NaN values when counting columns or rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ...\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import math\n",
    "names = ['sleep_question', 'sleep_mean', 'sleep_std', 'sample_size']\n",
    "for name in names:\n",
    "    assert(name in vars()), \"Double check that your variables are named correctly.\"\n",
    "assert(math.isclose(df_hello[sleep_question].var(), 1.3946600177662924)),\"Double check the column question text you've defined in 'sleep_question'.\" \n",
    "assert(math.isclose(sleep_mean, 7.171311475409836)), \"Your 'sleep_mean' is incorrect.\"\n",
    "assert(math.isclose(sleep_std, 1.1809572463752838)), \"Your 'sleep_std' is incorrect.\"\n",
    "assert(sample_size**2 / 8 == 46512.5), \"Your 'sample_size' is incorrect. Make sure you are excluding empty values when finding the sample size.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.2: Finding our P-value\n",
    "Now that we've **calculated and stored** the necessary statistics, we can begin calculating the **p-value** and drawing conclusions about our hypotheses. For the purposes of this lab, we will utilize a significance level of $0.05$. \n",
    "\n",
    "Make sure to remember whether we are doing a one tailed or two-tailed z-test when finding your p-value! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Now, calculate the **standard error** of the hours of sleep of DISCOVERY students, storing the result in the **numeric variable** `standard_error`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error = ...\n",
    "standard_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, **calculate our test statistic** given the `sleep_mean` and `standard_error` found above, storing the result in the **numeric variable** `z_stat`. \n",
    "\n",
    "Remember: $z = \\frac{\\text{value - EV}}{\\text{SE}}$, where $z$ is the test statistic for a z-test :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_stat = ...\n",
    "z_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we can calculate our p-value! Find it and store our p-value in the **variable** `p_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "p_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remember, the p-value is the probability of getting the data we have in DISCOVERY's `df_hello` or something even more extreme **if the null were true**."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "names = ['standard_error', 'z_stat', 'p_value']\n",
    "for name in names:\n",
    "    assert(name in vars()), \"Double check that your variables are named correctly.\"\n",
    "assert(math.isclose(standard_error, 0.04781556125339877)), \"Your 'standard_error' is incorrect.\"\n",
    "assert(math.isclose(z_stat, 7.765494447342563)), \"Your 'z_stat' is incorrect.\"\n",
    "assert(math.isclose(p_value, 8.215650382226158e-15, abs_tol=1e-15)), \"Your 'p_value' is incorrect. Try and visualize the normal distribution and the areas to the left or right of your z-stat.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Interpretation \n",
    "**Q2: We have now calculated the p-value for our hypothesis test. Do we reject the null hypothesis? Explain why or why not. Explain what this means in the context of our original question: Do UIUC students get significantly different sleep compared to the average American? Make sure you answer *both* questions.** \n",
    "\n",
    "Remember, our significance level is $0.05$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answers. ‚úèÔ∏è)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing it in Python\n",
    "We had to do a significant amount of calculations by hand to find our p-value. \n",
    "\n",
    "Luckily, Python has a few **libraries** which contain **functions** that allow us to conduct our hypothesis tests without doing the calculations by hand. \n",
    "\n",
    "Before we run these hypothesis test functions, we must **install** and `import` the library they belong to. \n",
    "\n",
    "To install the `statsmodels` library, try running any one of following commands in your **terminal** until successful installation:\n",
    "- `python3 -m pip install statsmodels`\n",
    "- `py -m pip install statsmodels`\n",
    "- `pip install statsmodels`\n",
    "- `pip3 install statsmodels`\n",
    "\n",
    "\n",
    "Then, **run** the following `import` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "This imports the `weightstats` class from the `statsmodels.stats` library, containing the function we need to perform **z-tests** in Python.\n",
    "\n",
    "The function we will be using is `weightstats.ztest()`. This function will take **three parameters** in the following order:\n",
    "1. A `list` of sampled values, where a `df[\"column\"]` is something that can be read as a list\n",
    "2. The **expected value** of the null hypothesis, specified using `value=`\n",
    "3. The **alternative hypothesis** to the null value (either 'two-sided', 'larger', or 'smaller', specified using `alternative=`)\n",
    "\n",
    "To learn more about **z-test function**, visit: https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ztest.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.3: z-test in Python\n",
    "Now, let's run the our z-test! Using the cell below, call the `ztest()` function to conduct our z-test and store the results in the variable `sleep_results`.\n",
    "\n",
    "Use your knowledge about our **type of hypothesis test** and the **national sleep average** to fill in the `...`\n",
    "- **IMPORTANT**: When doing the test, you must use `df[\"column\"].dropna()` to make sure to not include any `NaN values` since this z-test function requires that there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_results = ...\n",
    "sleep_results"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "If you print `sleep_results`, it should be a pair of **two values** in the form of $(z, p)$ where $z$ is the test statistic and $p$ is the `p-value`. If done correctly, these values should be **almost identical** to what you calculated by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "assert('sleep_results' in vars()), \"Double check your variable name for z-test result. It should be named 'sleep_results'.\"\n",
    "assert(math.isclose(sleep_results[0], 7.765494447342565)), \"The z-stat of your z-test is incorrect.\"\n",
    "assert(math.isclose(sleep_results[1], 8.132732814705086e-15)), \"The p-value of your z-test is incorrect.\"\n",
    "assert(math.isclose(sleep_results[0], z_stat)), \"Your z-stat from sleep_result should be equivalent to the 'z_stat' variable defined earlier.\"\n",
    "assert(math.isclose(sleep_results[1], p_value, abs_tol = 1e-15)), \"Your p-value from sleep_result should be equivalent to the 'p-value' variable defined earlier.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.4: How many classes are you taking this semester?\n",
    "Our knowledge of the `weightstats.ztest()` function from above lets us conduct a hypothesis test on any of our columns with ease. One question you all answered on the Hello Survey was *\"How many classes are you taking this semester?\"*. We will answer the following question by performing a z-test:\n",
    "> **Assuming the average college student is taking 5 classes in a semester, do UIUC students take *more* classes than the average college student?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Our Hypotheses\n",
    "**Q3: Define the null and alternative hypotheses using the cell below. Remember, we assume the average college student takes 5 classes each semester and believe UIUC students may take *more*. Think about whether or not this is a one sided or two sided test.** "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answers. ‚úèÔ∏è)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can assume again that our Hello Dataset is equivalent to a **random sample** of UIUC students. Conveniently, `df_hello` contains the number of courses students are taking this semester under the **column** named `\"How many classes are you taking this semester?\"`.\n",
    "\n",
    "To begin, assign this column name to a **string variable** named `course_question` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.5: Conducting the Hypothesis Test\n",
    "\n",
    "Now we have everything ready to conduct our **z-test**. \n",
    "\n",
    "Using the cell below, conduct the z-test and store the results in the variable `course_results`.\n",
    "\n",
    "- **Remember**, when doing the test, you'll want to use `df[\"column\"].dropna()` to make sure to not include any `NaN values` since this z-test requires that there are no missing values.\n",
    "- You may need to refer to the documentation to find out how to specify the correct alterative (https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ztest.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_results = ...\n",
    "course_results"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "assert('course_results' in vars()), \"Double check your variable name for z-test result. It should be named 'course_results'.\"\n",
    "assert(math.isclose(course_results[0], 0.4711032900655237)), \"The z-stat of your z-test is incorrect.\"\n",
    "assert(math.isclose(course_results[1], 0.3187834878779042)), \"The p-value of your z-test is incorrect.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Interpretation \n",
    "**Q4: We have now calculated the p-value for our hypothesis test. Do we reject the null hypothesis? Explain why or why not. Make sure to explain what this means in the context of our original question. Make sure you answer *all* parts of this question.** \n",
    "\n",
    "Remember, our significance level is $0.05$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answers. ‚úèÔ∏è)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Happiness and Credit Hours\n",
    "Let's do another hypothesis test! This time we are going to look at the relationship between happiness and credit hours! \n",
    "\n",
    "Taking random samples of student subgroups from `df_hello`, we may answer the following question:\n",
    "- **Are students who take less credit hours significantly *happier* than students who take more?**\n",
    "\n",
    "To answer, we will perform a **one-sided two-sample z-test**. Two-sample z-tests compare two samples to each other and are very common in statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Our Hypotheses\n",
    "**Q5: Define the null and alternative hypotheses using the cell below.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answers. ‚úèÔ∏è)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 2.1: Setting Up\n",
    "Now, let's run the our z-test! \n",
    "\n",
    "To make our code **simpler and readable**, in the next cell, create two variables for future column subselection from our `df_hello`:\n",
    "1. A **string variable** named `credits_question`, containing the **string**: \"How many credit hours are you taking?\"\n",
    "2. A **string variable** named `happiness_question`, containing the **string**:  \"From 1 to 10, how happy are you right now?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_question = ...\n",
    "happiness_question = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Again, we will need to **clean** our DataFrame before conducting these tests. Here's a list of issues we will need to take care of before doing our two sample z-test:\n",
    "- Some people responded with **unreasonable** answers to the `credits_question` (any answer **above 25** does not make sense)\n",
    "- Some people responded with **unreasonable** answers to the `happiness_question` (any answer **above 10** does not make sense because of the 1-10 scale)\n",
    "- By checking the values for each question, these conditionals will also remove all `NaN` values!  *(Python defines `NaN` to be not greater than or less than anything, so it's always `False` and will always be removed when checked with a conditional.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = ...\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî¨ Test Case Checkpoint üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "assert(math.isclose(df_clean[credits_question].std(), 2.16195279874247)), \"Double check the column question text you've defined in 'credits_question'.\" \n",
    "assert(math.isclose(df_clean[happiness_question].var(), 4.117011416494833)), \"Double check the column question text you've defined in 'happiness_question'.\" \n",
    "assert('df_clean' in vars()), \"Your new DataFrame should be named df_clean.\"\n",
    "assert(df_clean[credits_question].isnull().any() == False), \"There are still NaN values in the credits_question column.\"\n",
    "assert(df_clean[happiness_question].isnull().any() == False), \"There are still NaN values in the happiness_question column.\"\n",
    "assert(len(df_clean) == 606), \"Double check that you've cleaned NaN values from both question columns as well as the out-of-bounds values specified in the instructions.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now that we have cleaned our columns in `df_clean`, we can continue with our z-test setup. \n",
    "\n",
    "For this, we will consider **15 or more credit hours** as **\"many\"**. \n",
    "\n",
    "Using your `credits_question` variable, create **two** new `DataFrames`: \n",
    "- `df_many_credits`, containing the rows from `df_clean` with students taking **15 or more** credit hours. \n",
    "- `df_less_credits`, containing the rows from `df_clean` with students taking **less than 15** credit hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_many_credits = ...\n",
    "df_many_credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_less_credits = ...\n",
    "df_less_credits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 2.2: Conducting the Test\n",
    "Now we have the samples we need for our **two-sample z-test**.\n",
    "\n",
    "Now, let's run the our z-test! Using the cell below, call the `ztest()` function to conduct our z-test and store the results in the variable `happy_results`.\n",
    "\n",
    "- Hint: See the documentation on the z-test to see how to do a two sample z-test if you forgot! It's very similar to the one-sample z-tests we did in the previous puzzles!  https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ztest.html\n",
    "- When choosing the order of your lists and the `alternative` parameter for the `ztest()` function, know that your choice for the `alternative` parameter will be the relationship of your **first list** to your **second list**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_results = ...\n",
    "happy_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Interpretation \n",
    "**Q6: We have now calculated the p-value for our hypothesis test. Do we reject the null hypothesis? Why or why not? What does this mean in the context of our original question: Are students who take less credit hours significantly happier than students who take more? Ensure you answer *this entire* question**.\n",
    "\n",
    "Remember, our significance level is $0.05$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "*(‚úèÔ∏è Edit this cell to replace this text with your answers. ‚úèÔ∏è)*"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub:\n",
    "\n",
    "1.  ‚ö†Ô∏è **Make certain to save your work.** ‚ö†Ô∏è To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and follow the Canvas instructions to commit this lab to your Git repository!\n",
    "\n",
    "3. Your TA will grade your submission and provide you feedback after the lab is due. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e4deb337457fa8947131008f75dc159c243dc668058f6d523698d9cd505a843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
